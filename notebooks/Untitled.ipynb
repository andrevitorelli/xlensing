{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07b20dc-9aef-4063-b0a2-124f7088db03",
   "metadata": {},
   "source": [
    "# Xlensing Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa615b3-2478-48b3-8ebd-69b848f097ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28eac02b-3b91-4836-a957-0417e5d148c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup table loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#plots\n",
    "from matplotlib import pyplot as plt\n",
    "from getdist import plots, MCSamples\n",
    "\n",
    "#astrophysics\n",
    "#import galsim\n",
    "import xlensing\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "\n",
    "#saving\n",
    "from astropy.table import Table\n",
    "import pickle\n",
    "\n",
    "#MCMC\n",
    "import emcee\n",
    "\n",
    "#utilities\n",
    "#import os\n",
    "import time\n",
    "import warnings\n",
    "import tqdm\n",
    "\n",
    "#let's use multiprocessing\n",
    "from multiprocessing import Pool, freeze_support, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c116c3-d7ea-4977-b983-76fb360ec89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'xlensing' from '/local/home/az264973/github/xlensing/xlensing/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27330e38-a3d5-48ff-9c59-4b48e01a561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Total galaxies available per bin:\n",
      "[348, 550, 931, 1564, 2715, 4636, 7608, 13129]\n",
      "\n",
      "Single cluster:\n",
      "Separating galaxies per radial bin...\n",
      "Done in 5.001569747924805 seconds.\n",
      "Running MCMC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [03:30<03:30, 210.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 202.15543842315674 seconds.\n",
      "0.7546087380932999\n",
      "1.5307293552274792\n",
      "1\n",
      "Total galaxies available per bin:\n",
      "[288, 541, 994, 1611, 2721, 4768, 7782, 13039]\n",
      "\n",
      "Single cluster:\n",
      "Separating galaxies per radial bin...\n",
      "Done in 4.944668769836426 seconds.\n",
      "Running MCMC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [06:56<00:00, 208.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 197.3739402294159 seconds.\n",
      "0.6964969411359959\n",
      "0.9271860106396541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "M200true = 2e14\n",
    "C200true = 3.5\n",
    "Zcluster = 0.3\n",
    "RAcluster = 0.0 #radians \n",
    "DECluster = 0.0 #radians\n",
    "Ngals = 1e5\n",
    "\n",
    "mratio_list = []\n",
    "cratio_list = []\n",
    "\n",
    "for i in tqdm.tqdm(range(2)):\n",
    "  \n",
    "  E1gals, E2gals, RAgals, DECgals, Zgals = xlensing.testing.gen_gal(Ngals=Ngals,Zcluster=Zcluster)\n",
    "\n",
    "\n",
    "  epsilon = xlensing.testing.NFW_shear( (M200true,C200true, 0, 0, .3),(RAgals, DECgals, Zgals, E1gals, E2gals) )\n",
    "  e1gals = np.real(epsilon)\n",
    "  e2gals = np.imag(epsilon)\n",
    "\n",
    "  e1err = np.array([np.abs(np.random.normal(e/100,np.abs(e/20))) for e in e1gals])\n",
    "  e2err = np.array([np.abs(np.random.normal(e/100,np.abs(e/20))) for e in e2gals])\n",
    "  Wgals = (0.1**2 + e1err**2 +e2err**2)/(0.1**2 + e1err**2 +e2err**2) #w=1\n",
    "  Mgals = -np.random.exponential(0.03,size=int(Ngals))*0\n",
    "  \n",
    "  galaxy_catalog = Table([RAgals,DECgals,Zgals,e1gals,e2gals, Wgals,Mgals],names=['RA','DEC','ZPHOT','E1','E2','WEIGHT','M'])\n",
    "\n",
    "\n",
    "  sr_RA = np.array(galaxy_catalog['RA'])\n",
    "  sr_DEC= np.array(galaxy_catalog['DEC'])\n",
    "  sr_z  = np.array(galaxy_catalog['ZPHOT'])\n",
    "  sr_E1 = np.array(galaxy_catalog['E1'])\n",
    "  sr_E2 = np.array(galaxy_catalog['E2'])\n",
    "  sr_W = np.array(galaxy_catalog['WEIGHT'])\n",
    "  sr_M = np.array(galaxy_catalog['M'])\n",
    "\n",
    "\n",
    "  clusters = Table([[RAcluster],[DECluster],[Zcluster]],names=['RA','DEC', 'Z'])\n",
    "  clusters['INDEX'] = np.array(range(len(clusters)))\n",
    "\n",
    "  pool = Pool(cpu_count()) \n",
    "\n",
    "\n",
    "  #We get a partial function with a constant galaxy catalogue to iterate with clusters.\n",
    "  \n",
    "  survey_lensing = partial(xlensing.data.cluster_lensing,sources=(sr_RA, \n",
    "                                                                  sr_DEC, \n",
    "                                                                  sr_z, \n",
    "                                                                  sr_E1, \n",
    "                                                                  sr_E2, \n",
    "                                                                  sr_W,\n",
    "                                                                  sr_M),radius=10.)\n",
    "\n",
    "  #Make a list of clusters to get lensing data\n",
    "  cl_RA=np.array(clusters['RA'])\n",
    "  cl_DEC= np.array(clusters['DEC'])\n",
    "  cl_z= np.array(clusters['Z'])\n",
    "  cl = np.array([cl_RA,cl_DEC,cl_z]).T\n",
    "  clz = zip(cl_RA,cl_DEC,cl_z)\n",
    "  clzlist = [x for x in clz]\n",
    "\n",
    "  results = pool.map(survey_lensing, clzlist)\n",
    "\n",
    "  stick = [clusters]\n",
    "  \n",
    "  \n",
    "  radii = np.logspace(-0.8,0.8,8)\n",
    "  N = len(radii)\n",
    "  bins_lims = np.logspace(np.log10(radii[0])+(np.log10(radii[0])-np.log10(radii[1]))/2,\n",
    "                          np.log10(radii[N-1])-(np.log10(radii[0])-np.log10(radii[1]))/2,N+1)\n",
    "  bins_lims = np.array([[bins_lims[i],bins_lims[i+1]] for i in range(N)])\n",
    "\n",
    "\n",
    "  Nboot=200\n",
    "  stick_results = []\n",
    "  for stake in stick:\n",
    "      t = time.time()\n",
    "      clusterbkgs = []\n",
    "      for index in stake['INDEX']:\n",
    "          Sigma_crit = np.array(results[index]['Critical Density'])\n",
    "          e_t = np.array(results[index]['Tangential Shear'])\n",
    "          e_x = np.array(results[index]['Cross Shear'])\n",
    "          W = np.array(results[index]['Weights'])\n",
    "          M = np.array(results[index]['Mult. Bias'])\n",
    "          R = np.array(results[index]['Radial Distance'])\n",
    "          clusterbkgs.append(np.array([Sigma_crit, e_t, e_x, W, R,M]))\n",
    "      print(len(clusterbkgs))\n",
    "      sigmas, sigmas_cov, xigmas, xigmas_cov = xlensing.data.stack(clusterbkgs,bins_lims,Nboot)\n",
    "      stick_results.append( ( sigmas, sigmas_cov, xigmas, xigmas_cov) )\n",
    "      print(\"Done in \" + str(time.time()-t) + \" seconds.\")\n",
    "     \n",
    "  def NFWsimple(theta,Z,radii):\n",
    "    logM200, C200  = theta\n",
    "    M200 = np.power(10,logM200)\n",
    "    result = xlensing.model.NFW_shear(M200, C200, Z, 1.0, 0.001, 1e10,radii)['NFW Signal'] #returns only the main shear signal - all other signals (incl cross signal) available see docstring\n",
    "    return result\n",
    "\n",
    "  M200lo, M200hi = 13, 15\n",
    "  C200lo, C200hi = 0, 10\n",
    "\n",
    "  priorM200 = xlensing.fitting.ln_flat_prior_maker(M200lo, M200hi,0)\n",
    "  priorC200 = xlensing.fitting.ln_flat_prior_maker(C200lo, C200hi,1)\n",
    "  #priorPCC = xlensing.fitting.ln_gaussian_prior_maker(0.75, 0.07,2) ##Zhang et al. 2019\n",
    "  prior = lambda theta : priorM200(theta) + priorC200(theta)# + priorPCC(theta)\n",
    "\n",
    "  ndim, nwalkers, steps = 2, 256, 256\n",
    "  samplestick = []\n",
    "  #for each stack, run MCMC\n",
    "  burnin=round(steps/4.)\n",
    "  for stickresult in stick_results:\n",
    "    mean_z = Zcluster\n",
    "\n",
    "    #build data likelihood\n",
    "    model = lambda theta: NFWsimple(theta,mean_z,radii)\n",
    "    likelihood = xlensing.fitting.ln_gaussian_likelihood_maker((stickresult[0],stickresult[1]),model)\n",
    "    posterior = lambda theta : likelihood(theta) +prior(theta)\n",
    "\n",
    "    #initialise walkers\n",
    "    pos = []\n",
    "    for i in range(nwalkers):\n",
    "        M200 = np.random.uniform(M200lo,M200hi)\n",
    "        C200 = np.random.uniform(C200lo,C200hi)\n",
    "        #PCC  = np.random.uniform(PCClo,PCChi)\n",
    "        pos.append(np.array([M200,C200]))\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, posterior)\n",
    "    print(\"Running MCMC...\")\n",
    "    t = time.time()\n",
    "    sampler.run_mcmc(pos, steps, rstate0=np.random.get_state())\n",
    "    print(\"Done in \" + str(time.time()-t) + \" seconds.\")\n",
    "    samples = sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "    samplestick.append(samples)\n",
    "  for samples in samplestick:\n",
    "    mvir_tru,conc_tru= map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), \n",
    "                           zip(*np.percentile(samples, [16, 50, 84],axis=0)))\n",
    "    #print(\"Mvir: {:.2e}\".format(mvir_tru[0]) + \" p {:.2e}\".format(mvir_tru[1]) + \" m {:.2e}\".format(mvir_tru[2]))\n",
    "    #print(\"Conc: {:.2f}\".format(conc_tru[0]) + \" p {:.2f}\".format(conc_tru[1]) + \" m {:.2f}\".format(conc_tru[2]))\n",
    "  \n",
    "  m_ratio = 10**mvir_tru[0]/M200true\n",
    "  c_ratio = conc_tru[0]/C200true\n",
    "  print(m_ratio)\n",
    "  print(c_ratio)\n",
    "  mratio_list.append(m_ratio)\n",
    "  cratio_list.append(c_ratio)\n",
    "  #np.save(\"mratio_lower_snr.npy\",np.array(mratio_list))\n",
    "  #np.save(\"cratio_lower_snr.npy\",np.array(cratio_list))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feff5fb-65bc-4043-b79b-03e296d38a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
