{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concentrations and the Age of Galaxy Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an application of the xlensing code over several surveys to investigate the relationship between cluster mass concentration and observables that may relate to mass accretion age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup table loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=400)\n",
    "from matplotlib import pyplot as plt\n",
    "from getdist import plots, MCSamples\n",
    "from astropy.table import Table\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import xlensing\n",
    "\n",
    "import emcee\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS82: A weak-lensing survey done on stripe 82 by CFHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS82_DIR = os.path.expanduser(\"~/Data/CS82_REDMAPPER\")\n",
    "CS82_SOURCES = \"sources_cleaner_final.fits\"\n",
    "CS82_CLUSTERS = \"tcpure.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sources_cleaner_final.fits'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CS82_SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DES: A multi probe modern survey on the south hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DES_DIR = \"Data/DES_REDMAPPER\"\n",
    "DES_SOURCES = \"sources_cleaner_final.fits\"\n",
    "DES_CLUSTERS = \"tcpure.fits\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS82 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources  = Table.read(os.path.join(CS82_DIR,CS82_SOURCES))\n",
    "clusters = Table.read(os.path.join(CS82_DIR,CS82_CLUSTERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS82_SOURCES2 = \"cs82_combined_lensfit_sources_nozcuts_aug_2015.fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=3091501</i>\n",
       "<table id=\"table140379588857424\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>RA</th><th>DEC</th><th>BPZ_ZPHOT</th><th>BPZ_LOW95</th><th>BPZ_ODDS</th><th>WEIGHT</th><th>M</th><th>E1CORR</th><th>E2CORR</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th></tr></thead>\n",
       "<tr><td>-24.69918173058005</td><td>-1.0244722207927224</td><td>1.25</td><td>0.1</td><td>0.40808</td><td>13.9551</td><td>-0.034325</td><td>0.13697599</td><td>0.236063</td></tr>\n",
       "<tr><td>-25.11671359217877</td><td>-1.0229941001552796</td><td>0.38</td><td>0.23</td><td>0.95527</td><td>15.4969</td><td>-0.000684</td><td>0.027918</td><td>-0.161017</td></tr>\n",
       "<tr><td>-25.113486639321934</td><td>-1.0234552707089264</td><td>0.66</td><td>0.48</td><td>0.87132</td><td>15.3687</td><td>-0.000158</td><td>-0.148118</td><td>0.137512</td></tr>\n",
       "<tr><td>-25.108944123579704</td><td>-1.0215600239686817</td><td>0.48</td><td>0.15</td><td>0.61343</td><td>11.1226</td><td>-0.032525</td><td>-0.262904</td><td>0.700844</td></tr>\n",
       "<tr><td>-25.210098782545572</td><td>-1.0212686890624931</td><td>0.87</td><td>0.15</td><td>0.54222</td><td>12.5195</td><td>-0.026663</td><td>-0.114856</td><td>0.22005899</td></tr>\n",
       "<tr><td>-24.737692704477354</td><td>-1.0213363942721754</td><td>0.32</td><td>0.191</td><td>0.99715</td><td>15.2731</td><td>-0.001205</td><td>0.313868</td><td>-0.109652005</td></tr>\n",
       "<tr><td>-25.04084649690043</td><td>-1.021474675107365</td><td>0.31</td><td>0.08</td><td>0.58817</td><td>14.2494</td><td>-0.004033</td><td>-0.224612</td><td>-0.43318102</td></tr>\n",
       "<tr><td>-24.496686640601865</td><td>-1.0211324445396226</td><td>0.4</td><td>0.15</td><td>0.69965</td><td>9.7677</td><td>-0.099137</td><td>-0.090606995</td><td>-0.094464995</td></tr>\n",
       "<tr><td>-24.587590676205878</td><td>-1.0211156088397502</td><td>0.86</td><td>0.51</td><td>0.73007</td><td>14.2706</td><td>-0.019731</td><td>0.176663</td><td>-0.318876</td></tr>\n",
       "<tr><td>-24.551436780906158</td><td>-1.0213863042452733</td><td>0.24</td><td>0.1</td><td>0.53856</td><td>15.1908</td><td>-0.000131</td><td>0.46008998</td><td>-0.53221005</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>-0.6248841562675693</td><td>-0.04350590346908556</td><td>0.91</td><td>0.55</td><td>0.80157</td><td>14.6584</td><td>-0.003108</td><td>0.133207</td><td>0.076693</td></tr>\n",
       "<tr><td>-1.1375250832808774</td><td>-0.0439562960940054</td><td>0.23</td><td>0.109</td><td>0.92781</td><td>15.5583</td><td>0.0</td><td>-0.302031</td><td>-0.019274</td></tr>\n",
       "<tr><td>-0.7512692626629018</td><td>-0.04328876471648126</td><td>0.7</td><td>0.533</td><td>1.0</td><td>14.0842</td><td>-0.000555</td><td>-0.439238</td><td>-0.38429698</td></tr>\n",
       "<tr><td>-1.3144090001119366</td><td>-0.043095276480036304</td><td>0.71</td><td>0.51</td><td>0.71101</td><td>14.8015</td><td>-0.017145</td><td>-0.219884</td><td>0.036056</td></tr>\n",
       "<tr><td>-1.3388571669842122</td><td>-0.043109891002941464</td><td>0.17</td><td>0.055</td><td>0.99878</td><td>15.563</td><td>0.0</td><td>0.38104</td><td>0.290782</td></tr>\n",
       "<tr><td>-0.9439361460727014</td><td>-0.04381650841784863</td><td>0.23</td><td>0.08</td><td>0.9331</td><td>15.3201</td><td>-0.000435</td><td>-0.25116402</td><td>0.25267202</td></tr>\n",
       "<tr><td>-0.761121443788852</td><td>-0.04326553356997606</td><td>0.23</td><td>0.109</td><td>0.97603</td><td>15.5395</td><td>-4.1e-05</td><td>0.021451</td><td>0.016289</td></tr>\n",
       "<tr><td>-1.301804149417137</td><td>-0.043976951458217006</td><td>0.46</td><td>0.14</td><td>0.57926</td><td>15.5344</td><td>-7e-06</td><td>0.013715999</td><td>0.447363</td></tr>\n",
       "<tr><td>-1.380931751052401</td><td>-0.04336079161143594</td><td>0.5</td><td>0.353</td><td>1.0</td><td>15.563</td><td>0.0</td><td>-0.328463</td><td>0.042292997</td></tr>\n",
       "<tr><td>-0.6424550120932508</td><td>-0.044759914927624385</td><td>0.03</td><td>0.0</td><td>0.98827</td><td>15.563</td><td>0.0</td><td>0.177359</td><td>-0.0043710005</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=3091501>\n",
       "         RA                  DEC          ...    E1CORR        E2CORR   \n",
       "      float64              float64        ...   float32       float32   \n",
       "------------------- --------------------- ... ------------ -------------\n",
       " -24.69918173058005   -1.0244722207927224 ...   0.13697599      0.236063\n",
       " -25.11671359217877   -1.0229941001552796 ...     0.027918     -0.161017\n",
       "-25.113486639321934   -1.0234552707089264 ...    -0.148118      0.137512\n",
       "-25.108944123579704   -1.0215600239686817 ...    -0.262904      0.700844\n",
       "-25.210098782545572   -1.0212686890624931 ...    -0.114856    0.22005899\n",
       "-24.737692704477354   -1.0213363942721754 ...     0.313868  -0.109652005\n",
       " -25.04084649690043    -1.021474675107365 ...    -0.224612   -0.43318102\n",
       "-24.496686640601865   -1.0211324445396226 ... -0.090606995  -0.094464995\n",
       "-24.587590676205878   -1.0211156088397502 ...     0.176663     -0.318876\n",
       "-24.551436780906158   -1.0213863042452733 ...   0.46008998   -0.53221005\n",
       "                ...                   ... ...          ...           ...\n",
       "-0.6248841562675693  -0.04350590346908556 ...     0.133207      0.076693\n",
       "-1.1375250832808774   -0.0439562960940054 ...    -0.302031     -0.019274\n",
       "-0.7512692626629018  -0.04328876471648126 ...    -0.439238   -0.38429698\n",
       "-1.3144090001119366 -0.043095276480036304 ...    -0.219884      0.036056\n",
       "-1.3388571669842122 -0.043109891002941464 ...      0.38104      0.290782\n",
       "-0.9439361460727014  -0.04381650841784863 ...  -0.25116402    0.25267202\n",
       " -0.761121443788852  -0.04326553356997606 ...     0.021451      0.016289\n",
       " -1.301804149417137 -0.043976951458217006 ...  0.013715999      0.447363\n",
       " -1.380931751052401  -0.04336079161143594 ...    -0.328463   0.042292997\n",
       "-0.6424550120932508 -0.044759914927624385 ...     0.177359 -0.0043710005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sources2  = Table.read(os.path.join(CS82_DIR,CS82_SOURCES2))\n",
    "sources2 = sources2[(sources2['MAG_AUTO']<23.5) & (sources2['WEIGHT']>0) & (sources2['BPZ_ZPHOT']>0)& (sources2['BPZ_ODDS']>0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['RA_RAD'] = np.radians(clusters['RA'])\n",
    "clusters['DEC_RAD']= np.radians(clusters['DEC'])\n",
    "clusters['loc'] = np.array([i for i in range(len(clusters))])\n",
    "\n",
    "sr_RA = np.radians(np.array(sources['RA']))\n",
    "sr_DEC= np.radians(np.array(sources['DEC']))\n",
    "sr_z  = np.array(sources['BPZ_ZPHOT'])\n",
    "#sr_z95low= np.array(sources2['BPZ_LOW95'])\n",
    "sr_E1 = np.array(sources['E1CORR'])\n",
    "sr_E2 = np.array(sources['E2CORR'])\n",
    "sr_W = np.array(sources['WEIGHT'])\n",
    "sr_M = np.array(sources['M'])\n",
    "\n",
    "clusters['INDEX'] = np.array(range(len(clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_RA=np.radians(np.array(clusters['RA']))\n",
    "cl_DEC= np.radians(np.array(clusters['DEC']))\n",
    "cl_z= np.array(clusters['Z'])\n",
    "cl = np.array([cl_RA,cl_DEC,cl_z]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting lensing signal for all clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use multiprocessing\n",
    "from multiprocessing import Pool, freeze_support, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "# you can use whatever, but your machine core count is usually a good choice (although maybe not the best)\n",
    "pool = Pool(8) \n",
    "\n",
    "\n",
    "#We get a partial function with a constant galaxy catalogue to iterate with clusters.\n",
    "survey_lensing = partial(xlensing.data.cluster_lensing,sources=(sr_RA, sr_DEC, sr_z, sr_E1, sr_E2, sr_W,sr_M),radius=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of clusters to get lensing data\n",
    "clz = zip(cl_RA,cl_DEC,cl_z)\n",
    "clzlist = [x for x in clz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pool.map(survey_lensing, clzlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"Results/CS82/CS82_lensing_results.pickle\",\"wb\")\n",
    "#pickle.dump(results, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking CS82 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14384499, 0.17462454],\n",
       "       [0.17462454, 0.2119902 ],\n",
       "       [0.2119902 , 0.25735127],\n",
       "       [0.25735127, 0.31241857],\n",
       "       [0.31241857, 0.37926902],\n",
       "       [0.37926902, 0.46042394],\n",
       "       [0.46042394, 0.55894416],\n",
       "       [0.55894416, 0.67854546],\n",
       "       [0.67854546, 0.82373871],\n",
       "       [0.82373871, 1.        ],\n",
       "       [1.        , 1.21397719],\n",
       "       [1.21397719, 1.47374062],\n",
       "       [1.47374062, 1.78908749],\n",
       "       [1.78908749, 2.1719114 ],\n",
       "       [2.1719114 , 2.6366509 ],\n",
       "       [2.6366509 , 3.20083405],\n",
       "       [3.20083405, 3.88573952],\n",
       "       [3.88573952, 4.71719914],\n",
       "       [4.71719914, 5.72657215],\n",
       "       [5.72657215, 6.95192796]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radii = np.logspace(-.8,0.8,20)\n",
    "N = len(radii)\n",
    "bins_lims = np.logspace(np.log10(radii[0])+(np.log10(radii[0])-np.log10(radii[1]))/2,\n",
    "                        np.log10(radii[N-1])-(np.log10(radii[0])-np.log10(radii[1]))/2,N+1)\n",
    "bins_lims = np.array([[bins_lims[i],bins_lims[i+1]] for i in range(N)])\n",
    "bins_lims #in Mpc/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEM_MATCH_ID',\n",
       " 'RA',\n",
       " 'DEC',\n",
       " 'MODEL_MAG',\n",
       " 'MODEL_MAGERR',\n",
       " 'IMAG',\n",
       " 'IMAG_ERR',\n",
       " 'ZRED',\n",
       " 'ZRED_E',\n",
       " 'BCG_SPEC_Z',\n",
       " 'Z_SPEC_INIT',\n",
       " 'Z_INIT',\n",
       " 'Z',\n",
       " 'LAMBDA_CHISQ',\n",
       " 'LAMBDA_CHISQ_E',\n",
       " 'R_LAMBDA',\n",
       " 'SCALEVAL',\n",
       " 'MASKFRAC',\n",
       " 'C_LAMBDA',\n",
       " 'C_LAMBDA_ERR',\n",
       " 'MAG_LAMBDA_ERR',\n",
       " 'Z_LAMBDA',\n",
       " 'Z_LAMBDA_E',\n",
       " 'PHOTOID',\n",
       " 'LNLAMLIKE',\n",
       " 'LNBCGLIKE',\n",
       " 'LNLIKE',\n",
       " 'PZBINS',\n",
       " 'PZ',\n",
       " 'NCROSS',\n",
       " 'CHISQ',\n",
       " 'RMASK',\n",
       " 'RA_ORIG',\n",
       " 'DEC_ORIG',\n",
       " 'W',\n",
       " 'DLAMBDA_DZ',\n",
       " 'DLAMBDA_DZ2',\n",
       " 'LAMBDA_CHISQ_C',\n",
       " 'LAMBDA_CHISQ_CE',\n",
       " 'NCENT',\n",
       " 'NCENT_GOOD',\n",
       " 'RA_CENT',\n",
       " 'DEC_CENT',\n",
       " 'LAMBDA_CHISQ_CENT',\n",
       " 'P_BCG',\n",
       " 'P_CEN',\n",
       " 'Q_CEN',\n",
       " 'P_FG',\n",
       " 'Q_MISS',\n",
       " 'P_SAT',\n",
       " 'P_C',\n",
       " 'BCG_ILUM',\n",
       " 'ILUM',\n",
       " 'Z_LAMBDA_RAW',\n",
       " 'Z_LAMBDA_E_RAW',\n",
       " 'RMAG',\n",
       " 'RMAG_ERR',\n",
       " 'I_ABS',\n",
       " 'R_ABS',\n",
       " 'I_ABS_ERR',\n",
       " 'RC',\n",
       " 'RA_RAD',\n",
       " 'DEC_RAD',\n",
       " 'ANG_DIST',\n",
       " 'OFF',\n",
       " 'DELTA12',\n",
       " 'DELTA14',\n",
       " 'DELTA12_E',\n",
       " 'DELTA14_E',\n",
       " 'DELTA12i',\n",
       " 'DELTA14i',\n",
       " 'DELTA12i_E',\n",
       " 'DELTA14i_E',\n",
       " 'loc',\n",
       " 'INDEX']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of clusters in stack: 42\n",
      "mean, lowest, highest, redMaPPer richness:  28.5608 20.38486 53.22882\n",
      "# of clusters in stack: 42\n",
      "mean, lowest, highest, redMaPPer richness:  29.64899 20.14078 59.02571\n",
      "# of clusters in stack: 43\n",
      "mean, lowest, highest, redMaPPer richness:  29.999043 20.14078 56.310326\n"
     ]
    }
   ],
   "source": [
    "conditions =           (clusters['LAMBDA_CHISQ']<60)&\\\n",
    "                      (clusters['LAMBDA_CHISQ']>20)\n",
    "\n",
    "clusters_lowz = clusters[(clusters['Z']>0.2)&\n",
    "                         (clusters['Z']<0.4)&\n",
    "                         conditions]\n",
    "\n",
    "cuts = 3\n",
    "observable = 'DELTA12'\n",
    "clusters_lowz.sort(observable)\n",
    "partitions = [x*100/cuts for x in range(1,cuts) ]\n",
    "\n",
    "split = list(np.percentile(np.array(range(len(clusters_lowz))),partitions).astype(int))\n",
    "lowz=np.split(np.array(clusters_lowz),split)\n",
    "\n",
    "stick = []\n",
    "for stake in lowz:\n",
    "    print(\"# of clusters in stack: {}\".format(len(stake)))\n",
    "    print(\"mean, lowest, highest, redMaPPer richness: \",np.mean(stake['LAMBDA_CHISQ']),min(stake['LAMBDA_CHISQ']),max(stake['LAMBDA_CHISQ']))\n",
    "    stick.append(Table(stake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nboot=500\n",
    "print(bins_lims)\n",
    "stick_results = []\n",
    "for stake in stick:\n",
    "    t = time.time()\n",
    "    clusterbkgs = []\n",
    "    for index in stake['INDEX']:\n",
    "        Sigma_crit = np.array(results[index]['Critical Density'])\n",
    "        e_t = np.array(results[index]['Tangential Shear'])\n",
    "        e_x = np.array(results[index]['Critical Density'])\n",
    "        W = np.array(results[index]['Weights'])\n",
    "        M = np.array(results[index]['Mult. Bias'])\n",
    "        R = np.array(results[index]['Radial Distance'])\n",
    "        clusterbkgs.append(np.array([Sigma_crit, e_t, e_x, W, R,M]))\n",
    "    sigmas, sigmas_cov, xigmas, xigmas_cov = xlensing.data.stack(clusterbkgs,bins_lims,Nboot)\n",
    "    stick_results.append( ( sigmas, sigmas_cov, xigmas, xigmas_cov) )\n",
    "    print(\"Done in \" + str(time.time()-t) + \" seconds.\")\n",
    "\n",
    "#pickle_out2 = open(\"Results/CS82/CS82_stacking_results.pickle\",\"wb\")\n",
    "#pickle.dump(stick_results, pickle_out2)\n",
    "#pickle_out2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NFWsimple(theta,Z,radii):\n",
    "    M200, C200, PCC, SIGMAOFF  = theta\n",
    "    result = xlensing.model.NFW_shear(M200, C200, Z, PCC, SIGMAOFF, 0 ,radii) #+  xlensing.model.NFW_shear(M200, C200, Z, PCC, 0.65, 3.2e11,radii)['Miscentered Signal']\n",
    "    \n",
    "    return result['Signal'] #+ result['Miscentered Signal'] #result['Signal'] #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M200lo, M200hi = 1e13, 1e15\n",
    "C200lo, C200hi = 0, 20\n",
    "PCClo, PCChi = 0., 1\n",
    "SIGMAOFFlo, SIGMAOFFhi = 0.01, 0.1\n",
    "M0lo, M0hi = 0, 1e12\n",
    "\n",
    "priorM200 = xlensing.fitting.ln_flat_prior_maker(M200lo, M200hi,0)\n",
    "priorC200 = xlensing.fitting.ln_flat_prior_maker(C200lo, C200hi,1)\n",
    "priorPCC =xlensing.fitting.ln_gaussian_prior_maker(0.75, 0.08,2) ##Zhang et al. 2019\n",
    "priorSIGMAOFF = xlensing.fitting.ln_flat_prior_maker(SIGMAOFFlo, SIGMAOFFhi ,3)\n",
    "\n",
    "#priorSIGMAOFF = xlensing.fitting.ln_gaussian_prior_maker(0.42, 0.002,3)\n",
    "#priorM0       = xlensing.fitting.ln_flat_prior_maker(M0lo, M0hi,4)\n",
    "prior = lambda theta : priorM200(theta) + priorC200(theta) + priorPCC(theta) +priorSIGMAOFF(theta) # + priorM0(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers, steps = 4, 32, 4*512\n",
    "print(\"N/50 ={}\".format(steps/50))\n",
    "samplestick = []\n",
    "samplerstick= []\n",
    "#for each stack, run MCMC\n",
    "burnin=round(steps/4.)\n",
    "for stickresult in stick_results:\n",
    "    mean_z = np.average(stake['Z'])\n",
    "    #build data likelihood\n",
    "    model = lambda theta: NFWsimple(theta,mean_z,radii)\n",
    "    likelihood = xlensing.fitting.ln_gaussian_likelihood_maker((stickresult[0],stickresult[1]),model)\n",
    "    posterior = lambda theta : likelihood(theta) +prior(theta)\n",
    "\n",
    "    #initialise walkers\n",
    "    pos = []\n",
    "    for i in range(nwalkers):\n",
    "        M200 = np.random.uniform(M200lo,M200hi)\n",
    "        C200 = np.random.uniform(C200lo,C200hi)\n",
    "        PCC  = np.random.uniform(PCClo,PCChi)\n",
    "        SIGMAOFF = np.random.uniform(SIGMAOFFlo, SIGMAOFFhi)\n",
    "        #M0       = np.random.uniform(M0lo, M0hi)\n",
    "        pos.append(np.array([M200,C200,PCC,SIGMAOFF]))\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, posterior)\n",
    "    print(\"Running MCMC...\")\n",
    "    t = time.time()\n",
    "    sampler.run_mcmc(pos, steps, rstate0=np.random.get_state(),progress=True)\n",
    "    print(\"Done in \" + str(time.time()-t) + \" seconds.\")\n",
    "    print(sampler.get_autocorr_time(tol=0))\n",
    "    samples = sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "    samplestick.append(samples)\n",
    "    samplerstick.append(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samplers in samplerstick:\n",
    "    print(\"N/50 ={}\".format(steps/50))\n",
    "    print(samplers.get_autocorr_time(tol=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_out = open(\"Results/CS82/chains.pickle\",\"wb\")\n",
    "#pickle.dump(samplestick, pickle_out)\n",
    "#pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples in samplestick:\n",
    "    mvir_tru, conc_tru, pcc_tru, sigma_tru = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples, [16, 50, 84],axis=0)))\n",
    "    print(\"Mvir: {:.2e}\".format(mvir_tru[0]) + \" p {:.2e}\".format(mvir_tru[1]) + \" m {:.2e}\".format(mvir_tru[2]))\n",
    "    print(\"Conc: {:.2f}\".format(conc_tru[0]) + \" p {:.2f}\".format(conc_tru[1]) + \" m {:.2f}\".format(conc_tru[2]))\n",
    "    print(\"Pcc: {:.2f}\".format(pcc_tru[0]) + \" p {:.2f}\".format(pcc_tru[1]) + \" m {:.2f}\".format(pcc_tru[2]))\n",
    "    print(\"sigma_off: {:.2f}\".format(sigma_tru[0]) + \" p {:.2f}\".format(sigma_tru[1]) + \" m {:.2f}\".format(sigma_tru[2]))\n",
    "    #print(\"M0: {:.2e}\".format(m0_tru[0]) + \" p {:.2e}\".format(m0_tru[1]) + \" m {:.2e}\".format(m0_tru[2]))\n",
    "    print()\n",
    "\n",
    "labs =  [\"M_{200} [M_\\\\odot]\", \"c_{200}\",\"p_{cc}\",\"\\\\sigma_{off}\"]#,\"M_0\"]\n",
    "\n",
    "g = plots.getSubplotPlotter(width_inch=20)\n",
    "sample = [MCSamples(samples=samples, names = labs,labels=labs) for samples in samplestick]\n",
    "g.triangle_plot(sample,color=['r','g','b'],filled=True)\n",
    "#g.subplots[0,0].set_xlim(1e13,3e14)\n",
    "plt.savefig(\"triangle_plot_\"+observable+ \"_{}.pdf\".format(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,9))\n",
    "color = ['r','g','b']\n",
    "labels = [observable + \" \" + str(i) for i in range(cuts)]\n",
    "for i,stickresult in enumerate(stick_results):\n",
    "    plt.scatter(radii,np.array(stickresult[0]), c=color[i], label = labels[i])\n",
    "    plt.errorbar(radii,np.array(stickresult[0]),yerr=np.sqrt(np.diag(stickresult[1])),fmt='.',color=color[i])\n",
    "for i,samples in enumerate(samplestick):\n",
    "    mvir_tru,conc_tru,pcc_tru,sigma_tru = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples, [16, 50, 84],axis=0)))\n",
    "    theta = mvir_tru[0], conc_tru[0],pcc_tru[0],sigma_tru[0]#,0\n",
    "    fitcurve = model(theta)\n",
    "    plt.plot(radii,fitcurve,color=color[i])\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e0,1e3)\n",
    "plt.savefig('data_fit_'+observable+'_{}.pdf'.format(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building new likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single cluster:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stick=[cluster for cluster in clusters[clusters['Z']<0.4][0:10]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Nboot=500\n",
    "stick_results = []\n",
    "for stake in stick:\n",
    "    t = time.time()\n",
    "    clusterbkgs = []\n",
    "    index =stake['INDEX']\n",
    "    Sigma_crit = np.array(results[index]['Critical Density'])\n",
    "    e_t = np.array(results[index]['Tangential Shear'])\n",
    "    e_x = np.array(results[index]['Critical Density'])\n",
    "    W = np.array(results[index]['Weights'])\n",
    "    M = np.array(results[index]['Mult. Bias'])\n",
    "    R = np.array(results[index]['Radial Distance'])\n",
    "    clusterbkgs.append(np.array([Sigma_crit, e_t, e_x, W, R,M]))\n",
    "    sigmas, sigmas_cov, xigmas, xigmas_cov = xlensing.data.stack(clusterbkgs,bins_lims,Nboot)\n",
    "    stick_results.append( ( sigmas, sigmas_cov, xigmas, xigmas_cov) )\n",
    "    print(\"Done in \" + str(time.time()-t) + \" seconds.\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "plt.figure(figsize=(7,9))\n",
    "\n",
    "for stickresult in stick_results:\n",
    "    plt.scatter(radii,np.array(stickresult[0]))\n",
    "    plt.errorbar(radii,np.array(stickresult[0]),yerr=np.sqrt(np.diag(stickresult[1])),fmt='.')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig('data.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "ndim, nwalkers, steps = 3, 256, 256\n",
    "samplestick = []\n",
    "#for each stack, run MCMC\n",
    "burnin=round(steps/4.)\n",
    "for j in range(len(stick_results)):\n",
    "    stickresult = stick_results[j]\n",
    "    signal = sigmas\n",
    "    covariance = sigmas_cov\n",
    "    mean_z = np.average(stick[j]['Z'])\n",
    "\n",
    "    #build data likelihood\n",
    "    model = lambda theta: NFWsimple(theta,mean_z,radii)\n",
    "    likelihood = xlensing.fitting.ln_gaussian_likelihood_maker((stickresult[0],stickresult[1]),model)\n",
    "    posterior = lambda theta : likelihood(theta) +prior(theta)\n",
    "\n",
    "    #initialise walkers\n",
    "    pos = []\n",
    "    for i in range(nwalkers):\n",
    "        M200 = np.random.uniform(M200lo,M200hi)\n",
    "        C200 = np.random.uniform(C200lo,C200hi)\n",
    "        PCC  = np.random.uniform(PCClo,PCChi)\n",
    "        pos.append(np.array([M200,C200,PCC]))\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, posterior,threads=16)\n",
    "    print(\"Running MCMC...\")\n",
    "    t = time.time()\n",
    "    sampler.run_mcmc(pos, steps, rstate0=np.random.get_state())\n",
    "    print(\"Done in \" + str(time.time()-t) + \" seconds.\")\n",
    "    samples = sampler.chain[:, burnin:, :].reshape((-1, ndim))\n",
    "    samplestick.append(samples)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "for samples in samplestick:\n",
    "    mvir_tru,conc_tru,pcc_tru= map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples, [16, 50, 84],axis=0)))\n",
    "    print(\"Mvir: {:.2e}\".format(mvir_tru[0]) + \" p {:.2e}\".format(mvir_tru[1]) + \" m {:.2e}\".format(mvir_tru[2]))\n",
    "    print(\"Conc: {:.2f}\".format(conc_tru[0]) + \" p {:.2f}\".format(conc_tru[1]) + \" m {:.2f}\".format(conc_tru[2]))\n",
    "    print(\"Pcc: {:.2f}\".format(pcc_tru[0]) + \" p {:.2f}\".format(pcc_tru[1]) + \" m {:.2f}\".format(pcc_tru[2]))\n",
    "    print()\n",
    "\n",
    "labs =  [\"M_{200} [M_\\\\odot]\", \"c_{200}\",\"p_{cc}\"]\n",
    "\n",
    "g = plots.getSubplotPlotter(subplot_size=6)\n",
    "sample = [MCSamples(samples=samples, names = labs,labels=labs) for samples in samplestick[:-1]]\n",
    "\n",
    "g.triangle_plot(sample,filled=True)\n",
    "g.fig.savefig('single_clusters_lowz.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plan!\n",
    "\n",
    "Find a concentration - offset scaling relation like mass/lambda\n",
    "\n",
    "1. get a pivot/offset slope\n",
    "\n",
    "2. use a mass/lambda slope (redMaPPer)\n",
    "\n",
    "3. using  2, gets masses\n",
    "\n",
    "4. using 1 & 3 + m-C relation gets C - Diemer, Joyce\n",
    "\n",
    "5. NFW likelihood for each\n",
    "\n",
    "6. sum all likelihoods\n",
    "\n",
    "\n",
    "Input: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc_age(age,pivot,slope):\n",
    "    conc = pivot*age**slope\n",
    "    return conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate halo concentration from mass and redshift.\n",
    "\"\"\"\n",
    "\n",
    "def c_DuttonMaccio(z, m):\n",
    "    \"\"\"Concentration from c(M) relation in Dutton & Maccio (2014).\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : float or array_like\n",
    "        Redshift(s) of halos.\n",
    "    m : float or array_like\n",
    "        Mass(es) of halos (m200 definition), in units of solar masses.\n",
    "    h : float, optional\n",
    "        Hubble parameter. Default is from Planck13.\n",
    "    Returns\n",
    "    ----------\n",
    "    ndarray\n",
    "        Concentration values (c200) for halos.\n",
    "    References\n",
    "    ----------\n",
    "    Calculation from Planck-based results of simulations presented in:\n",
    "    A.A. Dutton & A.V. Maccio, \"Cold dark matter haloes in the Planck era:\n",
    "    evolution of structural parameters for Einasto and NFW profiles,\"\n",
    "    Monthly Notices of the Royal Astronomical Society, Volume 441, Issue 4,\n",
    "    p.3359-3374, 2014.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    a = 0.52 + 0.385 * np.exp(-0.617 * (z**1.21))  # EQ 10\n",
    "    b = -0.101 + 0.026 * z                         # EQ 11\n",
    "\n",
    "    logc200 = a + b * np.log10(m * 1 / (10.**12))  # EQ 7\n",
    "\n",
    "    concentration = 10.**logc200\n",
    "\n",
    "    return concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_DuttonMaccio(0.3,1e14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_lambda_MEP(Lambda):\n",
    "    Lambda0 = 40\n",
    "    M0 = 2.21E14\n",
    "    alpha = 1.18\n",
    "    \n",
    "    mass = M0*(Lambda/Lambda0)**alpha\n",
    "    \n",
    "    return mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{:.2e}\".format(mass_lambda_MEP(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colossus.halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colossus.cosmology import cosmology\n",
    "from colossus.halo import concentration\n",
    "\n",
    "cosmology.setCosmology('planck15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentration.concentration(1e14, '200c', 0.0, model = 'diemer15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newmodel(richness, age, Z, radii, theta):\n",
    "    \n",
    "    PCC, SIGMAOFF, pivot_conc_age, slope_conc_age = theta\n",
    "    \n",
    "    M200 = mass_lambda_MEP(richness)\n",
    "    C =  c_DuttonMaccio(Z,M200)\n",
    "    C200 = C*conc_age(age,pivot_conc_age, slope_conc_age)\n",
    "    \n",
    "    \n",
    "    result =xlensing.model.NFW_shear(M200, C200, Z, PCC, SIGMAOFF, 0 ,radii)['Signal']\n",
    "    \n",
    "    return result, M200, C, C200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (0.7, 0.4, 1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel(40, 2 , 0.3, radii, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
